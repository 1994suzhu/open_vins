<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Getting Started &raquo; Supported Datasets | Open VINS</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,600,600i%7CSource+Code+Pro:400,400i,600&amp;subset=latin-ext" />
  <link rel="stylesheet" href="m-dark+documentation.compiled.css" />
  <link rel="stylesheet" href="custom.css" />
  <link rel="icon" href="favicon-dark.png" type="image/png" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#22272e" />
</head>
<body>
<header><nav id="navigation">
  <div class="m-container">
    <div class="m-row">
      <a href="index.html" id="m-navbar-brand" class="m-col-t-8 m-col-m-none m-left-m">Open VINS</a>
      <div class="m-col-t-4 m-hide-m m-text-right m-nopadr">
        <a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
          <path d="m6 0c-3.3144 0-6 2.6856-6 6 0 3.3144 2.6856 6 6 6 1.4858 0 2.8463-0.54083 3.8945-1.4355-0.0164 0.33797 0.14734 0.75854 0.5 1.1504l3.2227 3.7891c0.55185 0.6139 1.4517 0.66544 2.002 0.11524 0.55022-0.55022 0.49866-1.4501-0.11524-2.002l-3.7891-3.2246c-0.39184-0.35266-0.81242-0.51469-1.1504-0.5 0.89472-1.0482 1.4355-2.4088 1.4355-3.8945 0-3.3128-2.6856-5.998-6-5.998zm0 1.5625a4.4375 4.4375 0 0 1 4.4375 4.4375 4.4375 4.4375 0 0 1-4.4375 4.4375 4.4375 4.4375 0 0 1-4.4375-4.4375 4.4375 4.4375 0 0 1 4.4375-4.4375z"/>
        </svg></a>
        <a id="m-navbar-show" href="#navigation" title="Show navigation"></a>
        <a id="m-navbar-hide" href="#" title="Hide navigation"></a>
      </div>
      <div id="m-navbar-collapse" class="m-col-t-12 m-show-m m-col-m-none m-right-m">
        <div class="m-row">
          <ol class="m-col-t-6 m-col-m-none">
            <li><a href="pages.html">Pages</a></li>
            <li><a href="namespaceov__core.html">ov_core</a></li>
            <li><a href="namespaceov__eval.html">ov_eval</a></li>
            <li><a href="namespaceov__msckf.html">ov_msckf</a></li>
            <li><a href="annotated.html">Classes</a></li>
          </ol>
          <ol class="m-col-t-6 m-col-m-none" start="6">
            <li><a href="https://github.com/rpng/open_vins/">GitHub</a></li>
            <li class="m-show-m"><a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
              <path d="m6 0c-3.3144 0-6 2.6856-6 6 0 3.3144 2.6856 6 6 6 1.4858 0 2.8463-0.54083 3.8945-1.4355-0.0164 0.33797 0.14734 0.75854 0.5 1.1504l3.2227 3.7891c0.55185 0.6139 1.4517 0.66544 2.002 0.11524 0.55022-0.55022 0.49866-1.4501-0.11524-2.002l-3.7891-3.2246c-0.39184-0.35266-0.81242-0.51469-1.1504-0.5 0.89472-1.0482 1.4355-2.4088 1.4355-3.8945 0-3.3128-2.6856-5.998-6-5.998zm0 1.5625a4.4375 4.4375 0 0 1 4.4375 4.4375 4.4375 4.4375 0 0 1-4.4375 4.4375 4.4375 4.4375 0 0 1-4.4375-4.4375 4.4375 4.4375 0 0 1 4.4375-4.4375z"/>
            </svg></a></li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</nav></header>
<main><article>
  <div class="m-container m-container-inflatable">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <h1>
          <span class="m-breadcrumb"><a href="getting-started.html">Getting Started</a> &raquo;</span>
          Supported Datasets
        </h1>
<section id="gs-data-euroc"><h2><a href="#gs-data-euroc">The EuRoC MAV Dataset</a></h2><p>The ETH ASL <a href="https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets">EuRoC MAV dataset</a> <a href="citelist.html#CITEREF_Burri2016IJRR" class="m-doc">[1]</a> is one of the most used datasets in the visual-inertial / simultaneous localization and mapping (SLAM) research literature. The reason for this is the synchronised inertial+camera sensor data and the high quality groundtruth. The dataset contains different sequences of varying difficulty of a Micro Aerial Vehicle (MAV) flying in an indoor room. Monochrome stereo images are collected by a two Aptina MT9V034 global shutter cameras at 20 frames per seconds, while a ADIS16448 MEMS inertial unit provides linear accelerations and angular velocities at a rate of 200 samples per second. We recommend that most users start testing on this dataset before moving on to the other datasets that our system support or before trying with your own collected data. Note that we also focus on the vicon room datasets as full 6 dof pose collection of the MAV was available.</p><aside class="m-block m-warning"><h3>Groundtruth on V1_01_easy</h3><p>We have found that the groundtruth on the V1_01_easy dataset is not accurate in its orientation estimate. We have recomputed this by optimizing the inertial and vicon readings in a graph to get the trajectory of the imu. You can find the output at this <a href="https://drive.google.com/drive/folders/1d62Q_RQwHzKLcIdUlTeBmojr7j0UL4sM?usp=sharing">link</a> and is what we normally use to evaluate the error on this dataset.</p></aside><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (m)</th><th>Dataset Link</th><th>Groundtruth Traj.</th><th>Example Launch</th></tr></thead><tbody><tr><td>Vicon Room 1 01</td><td>97</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_01_easy/V1_01_easy.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_eth.launch">launch</a></td></tr><tr><td>Vicon Room 1 02</td><td>96</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_02_medium/V1_02_medium.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_eth.launch">launch</a></td></tr><tr><td>Vicon Room 1 03</td><td>109</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_03_difficult/V1_03_difficult.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_eth.launch">launch</a></td></tr><tr><td>Vicon Room 2 01</td><td>72</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room2/V2_01_easy/V2_01_easy.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_eth.launch">launch</a></td></tr><tr><td>Vicon Room 2 02</td><td>103</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room2/V2_02_medium/V2_02_medium.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_eth.launch">launch</a></td></tr><tr><td>Vicon Room 2 03</td><td>111</td><td><a href="http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room2/V2_03_difficult/V2_03_difficult.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/euroc_mav">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_eth.launch">launch</a></td></tr></tbody></table></div></section><section id="gs-data-tumvi"><h2><a href="#gs-data-tumvi">TUM Visual-Inertial Dataset</a></h2><p>The TUM <a href="https://vision.in.tum.de/data/datasets/visual-inertial-dataset">Visual-Inertial Dataset</a> <a href="citelist.html#CITEREF_Schubert2018IROS" class="m-doc">[13]</a> is a more recent dataset that was presented to provide a way to evaluate state-of-the-art visual inertial odometery approaches. As compared to the EuRoC MAV datasets, this dataset provides photometric calibration of the cameras which has not been available in any other visual-inertal dataset for researchers. Monochrome stereo images are collected by two IDS uEye UI-3241LE-M-GL global shutter cameras at 20 frames per second, while a Bosch BMI160 inertial unit provides linear accelerations and angular velocities at a rate of 200 samples per second. Not all datasets have groundtruth avalible throughout the entire trajectory as the motion capture system is limited to the starting and ending room. There are quite a few very challenging outdoor handheld datasets which are a challenging direction for research. Note that we focus on the room datasets as full 6 dof pose collection is available over the total trajectory.</p><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (m)</th><th>Dataset Link</th><th>Groundtruth Traj.</th><th>Example Launch</th></tr></thead><tbody><tr><td>room1</td><td>239</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room1_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_tum.launch">launch</a></td></tr><tr><td>room2</td><td>203</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room2_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_tum.launch">launch</a></td></tr><tr><td>room3</td><td>194</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room3_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_tum.launch">launch</a></td></tr><tr><td>room4</td><td>122</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room4_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_tum.launch">launch</a></td></tr><tr><td>room5</td><td>255</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room5_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_tum.launch">launch</a></td></tr><tr><td>room6</td><td>99</td><td><a href="http://vision.in.tum.de/tumvi/calibrated/512_16/dataset-room6_512_16.bag">rosbag</a></td><td><a href="https://github.com/rpng/open_vins/tree/master/ov_data/tum_vi">link</a></td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_tum.launch">launch</a></td></tr></tbody></table></div></section><section id="gs-data-rpng"><h2><a href="#gs-data-rpng">RPNG Dataset</a></h2><p>In additional the above community maintained datasets, we have also released a few datasets. Please cite the Open VINS paper if you use any of these datasets in your works Most of these datasets do not have perfect calibration parameters, and some are not time synchronised. Thus, please ensure that you have enabled online calibration of these parameters.</p><div class="m-text-center"><table class="m-table"><thead><tr><th>Dataset Name</th><th>Length (m)</th><th>Dataset Link</th><th>Groundtruth Traj.</th><th>Example Launch</th></tr></thead><tbody><tr><td>ArUco Room 01</td><td>27</td><td><a href="https://drive.google.com/file/d/1ytjo8V6pCroaVd8-QSop7R4DbsvvKyRQ/view?usp=sharing">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_aruco.launch">launch</a></td></tr><tr><td>ArUco Room 02</td><td>93</td><td><a href="https://drive.google.com/file/d/1l_hnPUW6ufqxPtrLqRRHHI4mfGRZB1ha/view?usp=sharing">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_aruco.launch">launch</a></td></tr><tr><td>ArUco Hallway 01</td><td>190</td><td><a href="https://drive.google.com/file/d/1FQBo3uHqRd0qm8GUb50Q-sj5gukcwaoU/view?usp=sharing">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_aruco.launch">launch</a></td></tr><tr><td>ArUco Hallway 02</td><td>105</td><td><a href="https://drive.google.com/file/d/1oAbnV3MPOeaUSjnSc3g8t-pWV1nVjbys/view?usp=sharing">rosbag</a></td><td>none</td><td><a href="https://github.com/rpng/open_vins/blob/master/ov_msckf/launch/pgeneva_aruco.launch">launch</a></td></tr></tbody></table></div></section>
      </div>
    </div>
  </div>
</article></main>
<div class="m-doc-search" id="search">
  <a href="#!" onclick="return hideSearch()"></a>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-m-8 m-push-m-2">
        <div class="m-doc-search-header m-text m-small">
          <div><span class="m-label m-default">Tab</span> / <span class="m-label m-default">T</span> to search, <span class="m-label m-default">Esc</span> to close</div>
          <div id="search-symbolcount">&hellip;</div>
        </div>
        <div class="m-doc-search-content">
          <form>
            <input type="search" name="q" id="search-input" placeholder="Loading &hellip;" disabled="disabled" autofocus="autofocus" autocomplete="off" spellcheck="false" />
          </form>
          <noscript class="m-text m-danger m-text-center">Unlike everything else in the docs, the search functionality <em>requires</em> JavaScript.</noscript>
          <div id="search-help" class="m-text m-dim m-text-center">
            <p class="m-noindent">Search for symbols, directories, files, pages or
            modules. You can omit any prefix from the symbol or file path; adding a
            <code>:</code> or <code>/</code> suffix lists all members of given symbol or
            directory.</p>
            <p class="m-noindent">Use <span class="m-label m-dim">&darr;</span>
            / <span class="m-label m-dim">&uarr;</span> to navigate through the list,
            <span class="m-label m-dim">Enter</span> to go.
            <span class="m-label m-dim">Tab</span> autocompletes common prefix, you can
            copy a link to the result using <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">L</span> while <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">M</span> produces a Markdown link.</p>
          </div>
          <div id="search-notfound" class="m-text m-warning m-text-center">Sorry, nothing was found.</div>
          <ul id="search-results"></ul>
        </div>
      </div>
    </div>
  </div>
</div>
<script src="search.js"></script>
<script src="searchdata.js" async="async"></script>
<footer><nav>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <p>Generated by <a href="https://doxygen.org/">Doxygen</a> 1.8.16 and <a href="https://mcss.mosra.cz/">m.css</a>.</p>
      </div>
    </div>
  </div>
</nav></footer>
</body>
</html>
